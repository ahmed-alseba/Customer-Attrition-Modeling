# Customer-Attrition-Modeling
Improving the performance of the classification task on imbalanced data sets, where instances of one class occur more frequently than the other, poses a challenge on standard machine learning algorithms. This is especially important when misclassifying the minority class incurs more cost. In this paper, I apply random sampling and cost-sensitive learning techniques to bagging and boosting classifiers to improve the performance of the imbalanced customer attrition classification task using recent data from a telecommunications service provider. I find that combining random up-sampling with a boosting classifier, in the form of AdaBoost, produces the best results.
